{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you will gather all three pieces of data as described below in the \"Data Gathering\" section in the wrangle_act.ipynb notebook.\n",
    "\n",
    "In the cells below, gather **all** three pieces of data for this project and load them in the notebook. \n",
    "\n",
    "**Note:** the methods required to gather each data are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. The WeRateDogs Twitter archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We downloaded the `twitter-archive-enhanced.csv` from the Udacity platform and loaded it as a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. The tweet image predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We downloaded the `image-predictions.tsv` from the Udacity platform with `requests` and loaded it as a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Additional data from the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we couldn't get API from twitter, we used the `tweet-json.txt` file provided by the Udacity platform and loaded it as a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Displaying head and basic info of three dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We displayed the first lines of each of the three dataframes from files `twitter-archive-enhanced.csv`, `image-predictions.tsv` and `tweet-json.txt`.\n",
    "\n",
    "We also displayed the basic informations of the three dataframes to learn about their columns datatypes and detect inconsistencies and issues, both structural and tidiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many quality issues and tidiness issues we've detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "\n",
    "`twitter_archive_enhanced` dataframe:\n",
    "1. `in_reply_to_status_id`, `in_reply_to_user_id` are floats, must be integers\n",
    "\n",
    "2. `retweeted_status_id`, `retweeted_status_user_id` are floats, must be integers\n",
    "\n",
    "3. columns with  missing values: `expanded_urls`, `retweeted_status_id`, `retweeted_status_user_id`, `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_timestamp`\n",
    "\n",
    "4. columns that must be datetime format not string : `timestamp`, `retweeted_status_timestamp`\n",
    "\n",
    "`twitter_archive_from_api` dataframe:\n",
    "\n",
    "5. `tweet_id` are strings, must be integers\n",
    "\n",
    "6. columns that must be datetime format not string : `created_at`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "### Tidiness issues\n",
    "\n",
    "`twitter_archive_enhanced` dataframe:\n",
    "\n",
    "1. drop non existig `expanded_urls`\n",
    "\n",
    "2. separate tables for existing and non existing `expanded_urls`\n",
    "\n",
    "3. separate tables for existing and non existing `expanded_urls`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp` \n",
    "\n",
    "4. separate tables for existing and non existing `expanded_urls`, `in_reply_to_status_id`, `in_reply_to_user_id`\n",
    "\n",
    "`twitter_archive_from_api` dataframe:\n",
    "1. drop non existig `expanded_urls`\n",
    "\n",
    "2. missing rating colomns(rating numerator and rating denominator) all of that are in the text message\n",
    "\n",
    "3. missing dog's name. The dog's name is in the text message. Need extraction.\n",
    "\n",
    "Create a `master_twitter_archive` dataframe from the two dataframes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cleaned all the issues mentioned above. and created a master dataset and saved it as `twitter_archive_master.csv` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Quality Issue #1: `twitter_archive_enhanced` dataframe:\n",
    "1. `in_reply_to_status_id`, `in_reply_to_user_id` are floats, must be integers\n",
    "\n",
    "2. `retweeted_status_id`, `retweeted_status_user_id` are floats, must be integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "Convert datatype from float to integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Quality Issue #2: `twitter_archive_enhanced` dataframe:\n",
    "\n",
    "3. columns with  missing values: `expanded_urls`, `retweeted_status_id`, `retweeted_status_user_id`, `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "#### Define\n",
    "We can't deal with missing values. we'll leave missing values as they are. They represent a tidiness issue mentionned in the tidiness group. It will be solved in the tidiness solutions group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Quality Issue #3: `twitter_archive_enhanced` dataframe:\n",
    "\n",
    "4. columns that must be datetime format not string : `timestamp`, `retweeted_status_timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "Convert `timestamp`, `retweeted_status_timestamp` datatype from object to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Quality Issue #4:`twitter_archive_from_api` dataframe:\n",
    "5. `tweet_id` are strings, must be integers\n",
    "\n",
    "6. columns that must be datetime format not string : `created_at`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "Convert `tweet_id` datatype from object to integer\n",
    "\n",
    "Convert `created_at` datatype from object to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tidiness Issue #1:`twitter_archive_enhanced` dataframe:\n",
    "\n",
    "1. drop non existig `expanded_urls`\n",
    "\n",
    "2. separate tables for existing and non existing `expanded_urls`\n",
    "\n",
    "3. separate tables for existing and non existing `expanded_urls`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp` \n",
    "\n",
    "4. separate tables for existing and non existing `expanded_urls`, `in_reply_to_status_id`, `in_reply_to_user_id`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tidiness Issue #2:`twitter_archive_from_api` dataframe:\n",
    "\n",
    "1. drop non existig `expanded_urls`\n",
    "\n",
    "2. missing rating colomns(rating numerator and rating denominator) all of that are in the text message\n",
    "\n",
    "3. missing dog's name. The dog's name is in the text message. Need extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "Create a new datframe `api_missing_expanded_urls` by slicing the dataframe\n",
    "\n",
    "Drop rows with missing `expanded_urls`\n",
    "\n",
    "Create `rating_numerator` and `rating_denominator` columns by extracting `full_text` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness Issue #3: Create a `master_twitter_archive` dataframe from the two dataframes `ehd_twitter_clean` and `api_twitter_clean`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "\n",
    "1. Drop  `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp` in `ehd_twitter_clean` dataframe.\n",
    "\n",
    "2. Rename `timestamp` to `created_at` in  `ehd_twitter_clean` dataframe.\n",
    "\n",
    "3. Rename `text` in to `full_text` in `ehd_twitter_clean` dataframe.\n",
    "\n",
    "4. Keep only `tweet_id`, `retweet_count` and `favorite_count` in the `api_twitter_clean` dataframe drop all other columns. \n",
    "\n",
    "5. Operate the merge of the three dataframes `image_predictions`, `ehd_twitter_clean` and `api_twitter_clean` to have one `master_twitter_archive` dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1. There are more tweets from Iphone than other platforms.\n",
    "\n",
    "2. The most used rating numerator note is `12`.\n",
    "\n",
    "3. There is a high correlation between `retweet_count` and `favorite_count`\n",
    "\n",
    "4. Most of each image predictions are True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used three different visualisations:\n",
    "* Barplot\n",
    "* Pieplot\n",
    "* Heatmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
